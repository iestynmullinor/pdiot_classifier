import file_tagger
import sequence_genrator
import tensorflow as tf
import numpy as np
from keras import layers, Sequential, models
from sklearn.model_selection import train_test_split
from sklearn.model_selection import LeaveOneOut

# this is not used its just saved cus it has leave one out cross validation

GYRO = False
SEQUENCE_LENGTH = 5
SEQUENCE_OVERLAP = 4
BATCH_SIZE = 10
EPOCHS = 5
MODEL_NAME = f"physical_activity_epochs:{EPOCHS}_batch:{BATCH_SIZE}_gyro:{GYRO}_window:{SEQUENCE_LENGTH}_overlap:{SEQUENCE_OVERLAP}.keras"

DATA_DIRECTORY = "./all_respeck"
RESPIRATORY_ACTIVITIES = {
    "sitting&coughing",
    "sitting&hyperventilating",
    
    "standing&coughing",
    "standing&hyperventilating",
    
    "lying_down_back&coughing",
    "lying_down_back&hyperventilating",
    
    "lying_down_stomach&coughing",
    "lying_down_stomach&hyperventilating",
    
    "lying_down_right&coughing",
    "lying_down_right&hyperventilating",
    
    "lying_down_left&coughing",
    "lying_down_left&hyperventilating",
}

def generate_training_data(directory, sequence_length, overlap, gyro = GYRO): # if gyro is false, only accelerometer data is used

    tagged_data = []

    # group each csv file into their respective areas
    csv_dictionary = file_tagger.tag_directory(directory)

    # iterates through each activity
    for key in RESPIRATORY_ACTIVITIES:

        # iterates through each csv file for the activity 
        student_no = 0
        for csv_file in csv_dictionary[key]:
            if gyro:
                sequences = sequence_genrator.generate_sequences_from_file_with_gyroscope(directory + "/" + csv_file, sequence_length, overlap)
            else:
                sequences = sequence_genrator.generate_sequences_from_file_without_gyroscope(directory + "/" + csv_file, sequence_length, overlap)

            # iterate through each generated sequence
            for sequence in sequences:
                tagged_data.append((key, sequence, student_no))
            student_no += 1

    print ("there are " + str(len(tagged_data)) + " tagged sequences in the dataset")
    return tagged_data


tagged_sequences = generate_training_data(DATA_DIRECTORY, SEQUENCE_LENGTH, SEQUENCE_OVERLAP)


#CNN MODEL 
# removed validation data for now may need to add it back in
def train_model_CNN(input_data, labels_encoded, unique_labels, epochs, batch_size):
    if GYRO:
        width = 6
    else:
        width = 3
    # Define the CNN model for your specific input shape
    model = Sequential([
        layers.Conv1D(32, 3, activation='relu', input_shape=(SEQUENCE_LENGTH*25, width)),
        layers.MaxPooling1D(2),
        layers.Conv1D(64, 3, activation='relu'),
        layers.MaxPooling1D(2),
        layers.Conv1D(64, 3, activation='relu'),
        layers.MaxPooling1D(2),
        layers.Conv1D(128, 3, activation='relu'),
        layers.MaxPooling1D(2),
        layers.Dropout(0.5),
        layers.Flatten(),
        layers.Dense(64, activation='relu'),
        layers.Dense(len(unique_labels), activation='softmax')
    ])

    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Train the CNN model
    model.fit(input_data, labels_encoded, epochs=epochs, batch_size=batch_size)

    return model


# Leave One Out Cross Validation
loo = LeaveOneOut()

losses = []
accuracies = []
unique_student_nos = set([student_no for _, _, student_no in tagged_sequences])

# Loop over the splits generated by the LeaveOneOut function
for student_no_index in unique_student_nos:

    # Combine all sequences and labels
    training_sequences = [sequence for _, sequence, student_no in tagged_sequences if student_no != student_no_index]
    test_sequences = [sequence for _, sequence, student_no in tagged_sequences if student_no == student_no_index]

    training_labels = [label for label, _ , student_no in tagged_sequences if student_no != student_no_index]
    test_labels = [label for label, _ , student_no in tagged_sequences if student_no == student_no_index]

    # encode labels to numbers
    training_sequences = np.array(training_sequences, dtype=np.float32)
    test_sequences = np.array(test_sequences, dtype=np.float32)

    # encode labels to numbers
    label_to_index = {label: idx for idx, label in enumerate(RESPIRATORY_ACTIVITIES)}
    training_labels_encoded = [label_to_index[label] for label in training_labels]
    training_labels_encoded = np.array(training_labels_encoded)

    test_labels_encoded = [label_to_index[label] for label in test_labels]
    test_labels_encoded = np.array(test_labels_encoded)

    # Train the CNN model
    print("test set is student number: " + str(student_no_index) + " out of " + str(len(unique_student_nos)) + " students")
    model = train_model_CNN(training_sequences, training_labels_encoded, RESPIRATORY_ACTIVITIES, batch_size=BATCH_SIZE, epochs=EPOCHS)

    # Evaluate the model on the test set
    test_loss, test_accuracy = model.evaluate(test_sequences, test_labels_encoded)
    print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

    # Append the loss and accuracy to the respective lists
    losses.append(test_loss)
    accuracies.append(test_accuracy)


# Calculate and print the average loss and accuracy across all folds
average_loss = sum(losses) / len(losses)
average_accuracy = sum(accuracies) / len(accuracies)
print(f"Average Loss: {average_loss}, Average Accuracy: {average_accuracy}")

# Save the trained model
# model.save(f"models/Task2/{MODEL_NAME}_{average_accuracy}")