{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GYRO = False\n",
    "SEQUENCE_LENGTH = 5\n",
    "SEQUENCE_OVERLAP = 4\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS = 50\n",
    "MODEL_NAME = f\"other_activity_epochs:{EPOCHS}_batch:{BATCH_SIZE}_gyro:{GYRO}_window:{SEQUENCE_LENGTH}_overlap:{SEQUENCE_OVERLAP}.keras\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT THE VALUES IN THE CELL ABOVE THEN PRESS RUN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.file_tagger as file_tagger\n",
    "import helpers.sequence_generator as sequence_generator\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import layers, Sequential, models\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"./all_respeck\"\n",
    "OTHER_ACTIVITIES = {\n",
    "    \"sitting&talking\",\n",
    "    \"sitting&eating\",\n",
    "    \"sitting&singing\",\n",
    "    \"sitting&laughing\",\n",
    "    \n",
    "    \"standing&talking\",\n",
    "    \"standing&eating\",\n",
    "    \"standing&singing\",\n",
    "    \"standing&laughing\",\n",
    "    \n",
    "    \"lying_down_back&talking\",\n",
    "    \"lying_down_back&singing\",\n",
    "    \"lying_down_back&laughing\",\n",
    "    \n",
    "    \"lying_down_right&talking\",\n",
    "    \"lying_down_right&singing\",\n",
    "    \"lying_down_right&laughing\",\n",
    "    \n",
    "    \"lying_down_left&talking\",\n",
    "    \"lying_down_left&singing\",\n",
    "    \"lying_down_left&laughing\",\n",
    "    \n",
    "    \"lying_down_stomach&talking\",\n",
    "    \"lying_down_stomach&singing\",\n",
    "    \"lying_down_stomach&laughing\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(directory, sequence_length, overlap, gyro = GYRO): # if gyro is false, only accelerometer data is used\n",
    "\n",
    "    tagged_data = []\n",
    "\n",
    "    # group each csv file into their respective areas\n",
    "    csv_dictionary = file_tagger.tag_directory(directory)\n",
    "\n",
    "    # iterates through each activity\n",
    "    for key in OTHER_ACTIVITIES:\n",
    "\n",
    "        # iterates through each csv file for the activity \n",
    "        for csv_file in csv_dictionary[key]:\n",
    "            if gyro:\n",
    "                sequences = sequence_generator.generate_sequences_from_file_with_gyroscope(directory + \"/\" + csv_file, sequence_length, overlap)\n",
    "            else:\n",
    "                sequences = sequence_generator.generate_sequences_from_file_without_gyroscope(directory + \"/\" + csv_file, sequence_length, overlap)\n",
    "\n",
    "            # iterate through each generated sequence\n",
    "            for sequence in sequences:\n",
    "                tagged_data.append((key, sequence))\n",
    "\n",
    "    print (\"there are \" + str(len(tagged_data)) + \" tagged sequences in the dataset\")\n",
    "    return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, dev, and test sets\n",
    "def train_dev_test_split(data, labels, dev_size, test_size, random_state=42):\n",
    "    # Split the data into training and temporary (dev + test) sets\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=(dev_size + test_size), random_state=random_state)\n",
    "    \n",
    "    # Split the temporary data into dev and test sets\n",
    "    dev_data, test_data, dev_labels, test_labels = train_test_split(temp_data, temp_labels, \n",
    "                                                                 test_size=(test_size / (dev_size + test_size)), random_state=random_state)\n",
    "    \n",
    "    return train_data, dev_data, test_data, train_labels, dev_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 23873 tagged sequences in the dataset\n"
     ]
    }
   ],
   "source": [
    "tagged_sequences = generate_training_data(DATA_DIRECTORY, SEQUENCE_LENGTH, SEQUENCE_OVERLAP)\n",
    "\n",
    "# Combine all sequences and labels\n",
    "sequences = [sequence for _, sequence in tagged_sequences]\n",
    "labels = [label for label, _ in tagged_sequences]\n",
    "\n",
    "\n",
    "# encode labels to numbers\n",
    "sequences = np.array(sequences, dtype=np.float32)\n",
    "label_to_index = {label: idx for idx, label in enumerate(OTHER_ACTIVITIES)}\n",
    "labels_encoded = [label_to_index[label] for label in labels]\n",
    "labels_encoded = np.array(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN MODEL\n",
    "def train_model_CNN(input_data, labels_encoded, unique_labels, epochs, batch_size, validation_data):\n",
    "    if GYRO:\n",
    "        width = 6\n",
    "    else:\n",
    "        width = 3\n",
    "    # Define the CNN model for your specific input shape\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(32, 3, activation='relu', input_shape=(SEQUENCE_LENGTH*25, width)),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(128, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the CNN model\n",
    "    model.fit(input_data, labels_encoded, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1910/1910 [==============================] - 9s 4ms/step - loss: 1.6625 - accuracy: 0.2561 - val_loss: 1.5268 - val_accuracy: 0.2878\n",
      "Epoch 2/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.5148 - accuracy: 0.2963 - val_loss: 1.3371 - val_accuracy: 0.3758\n",
      "Epoch 3/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.2845 - accuracy: 0.3993 - val_loss: 1.0842 - val_accuracy: 0.5057\n",
      "Epoch 4/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.1132 - accuracy: 0.4771 - val_loss: 1.0089 - val_accuracy: 0.5228\n",
      "Epoch 5/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 1.0703 - accuracy: 0.5018 - val_loss: 1.1149 - val_accuracy: 0.4897\n",
      "Epoch 6/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.0366 - accuracy: 0.5182 - val_loss: 1.0313 - val_accuracy: 0.5220\n",
      "Epoch 7/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.0271 - accuracy: 0.5220 - val_loss: 1.0090 - val_accuracy: 0.5375\n",
      "Epoch 8/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.0065 - accuracy: 0.5303 - val_loss: 0.9382 - val_accuracy: 0.5605\n",
      "Epoch 9/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 1.0017 - accuracy: 0.5303 - val_loss: 1.0258 - val_accuracy: 0.5203\n",
      "Epoch 10/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9773 - accuracy: 0.5449 - val_loss: 0.9372 - val_accuracy: 0.5689\n",
      "Epoch 11/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9748 - accuracy: 0.5474 - val_loss: 0.9243 - val_accuracy: 0.5890\n",
      "Epoch 12/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9602 - accuracy: 0.5484 - val_loss: 0.9391 - val_accuracy: 0.5522\n",
      "Epoch 13/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9462 - accuracy: 0.5584 - val_loss: 0.9375 - val_accuracy: 0.5735\n",
      "Epoch 14/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9374 - accuracy: 0.5621 - val_loss: 0.9137 - val_accuracy: 0.5786\n",
      "Epoch 15/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9206 - accuracy: 0.5690 - val_loss: 0.9370 - val_accuracy: 0.5660\n",
      "Epoch 16/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.9130 - accuracy: 0.5725 - val_loss: 0.8992 - val_accuracy: 0.5773\n",
      "Epoch 17/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9021 - accuracy: 0.5801 - val_loss: 0.8653 - val_accuracy: 0.5865\n",
      "Epoch 18/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.9017 - accuracy: 0.5823 - val_loss: 0.8858 - val_accuracy: 0.5836\n",
      "Epoch 19/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8841 - accuracy: 0.5892 - val_loss: 0.8338 - val_accuracy: 0.6267\n",
      "Epoch 20/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8796 - accuracy: 0.5898 - val_loss: 0.8459 - val_accuracy: 0.5999\n",
      "Epoch 21/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.8628 - accuracy: 0.5914 - val_loss: 0.8206 - val_accuracy: 0.6041\n",
      "Epoch 22/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8619 - accuracy: 0.6041 - val_loss: 0.8512 - val_accuracy: 0.6049\n",
      "Epoch 23/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.8534 - accuracy: 0.6013 - val_loss: 0.8950 - val_accuracy: 0.5865\n",
      "Epoch 24/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8574 - accuracy: 0.6051 - val_loss: 0.7862 - val_accuracy: 0.6263\n",
      "Epoch 25/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.8280 - accuracy: 0.6151 - val_loss: 0.8614 - val_accuracy: 0.6137\n",
      "Epoch 26/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8282 - accuracy: 0.6157 - val_loss: 0.8391 - val_accuracy: 0.6238\n",
      "Epoch 27/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.8091 - accuracy: 0.6225 - val_loss: 0.7971 - val_accuracy: 0.6171\n",
      "Epoch 28/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8120 - accuracy: 0.6284 - val_loss: 0.7905 - val_accuracy: 0.6322\n",
      "Epoch 29/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.8089 - accuracy: 0.6251 - val_loss: 0.7861 - val_accuracy: 0.6326\n",
      "Epoch 30/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.8004 - accuracy: 0.6281 - val_loss: 0.7773 - val_accuracy: 0.6410\n",
      "Epoch 31/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7960 - accuracy: 0.6312 - val_loss: 0.7511 - val_accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.7828 - accuracy: 0.6378 - val_loss: 0.7973 - val_accuracy: 0.6276\n",
      "Epoch 33/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7880 - accuracy: 0.6373 - val_loss: 0.7781 - val_accuracy: 0.6401\n",
      "Epoch 34/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7728 - accuracy: 0.6433 - val_loss: 0.7488 - val_accuracy: 0.6649\n",
      "Epoch 35/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7691 - accuracy: 0.6453 - val_loss: 0.7203 - val_accuracy: 0.6607\n",
      "Epoch 36/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7529 - accuracy: 0.6511 - val_loss: 0.8016 - val_accuracy: 0.6473\n",
      "Epoch 37/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7579 - accuracy: 0.6461 - val_loss: 0.7244 - val_accuracy: 0.6682\n",
      "Epoch 38/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7428 - accuracy: 0.6551 - val_loss: 0.7686 - val_accuracy: 0.6569\n",
      "Epoch 39/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7470 - accuracy: 0.6608 - val_loss: 0.7412 - val_accuracy: 0.6506\n",
      "Epoch 40/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7444 - accuracy: 0.6581 - val_loss: 0.7308 - val_accuracy: 0.6615\n",
      "Epoch 41/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7366 - accuracy: 0.6640 - val_loss: 0.7025 - val_accuracy: 0.6653\n",
      "Epoch 42/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7362 - accuracy: 0.6618 - val_loss: 0.7068 - val_accuracy: 0.6632\n",
      "Epoch 43/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7244 - accuracy: 0.6676 - val_loss: 0.6955 - val_accuracy: 0.6716\n",
      "Epoch 44/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7107 - accuracy: 0.6740 - val_loss: 0.7143 - val_accuracy: 0.6678\n",
      "Epoch 45/50\n",
      "1910/1910 [==============================] - 7s 4ms/step - loss: 0.7191 - accuracy: 0.6730 - val_loss: 0.7055 - val_accuracy: 0.6736\n",
      "Epoch 46/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7180 - accuracy: 0.6686 - val_loss: 0.7008 - val_accuracy: 0.6745\n",
      "Epoch 47/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7030 - accuracy: 0.6777 - val_loss: 0.7117 - val_accuracy: 0.6632\n",
      "Epoch 48/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7180 - accuracy: 0.6771 - val_loss: 0.7126 - val_accuracy: 0.6703\n",
      "Epoch 49/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.7040 - accuracy: 0.6794 - val_loss: 0.6853 - val_accuracy: 0.6774\n",
      "Epoch 50/50\n",
      "1910/1910 [==============================] - 8s 4ms/step - loss: 0.6892 - accuracy: 0.6873 - val_loss: 0.6545 - val_accuracy: 0.6942\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6930\n",
      "Test Loss: 0.6716873645782471, Test Accuracy: 0.6930485963821411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 19:57:32.740566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-03 19:57:33.135207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,5,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Task3/other_activity_epochs:50_batch:10_gyro:False_window:5_overlap:4.keras_0.6930485963821411/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Task3/other_activity_epochs:50_batch:10_gyro:False_window:5_overlap:4.keras_0.6930485963821411/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, dev_data, test_data, train_labels, dev_labels, test_labels = train_dev_test_split(sequences, labels_encoded, dev_size=0.1, test_size=0.1) #10% dev, 10% test\n",
    "\n",
    "\n",
    "# train and save model (CHOOSE BETWEEN CNN AND LSTM)\n",
    "model = train_model_CNN(train_data, train_labels, OTHER_ACTIVITIES, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(dev_data, dev_labels)) #batch_size, epochs\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(f\"models/Task3/{MODEL_NAME}_{test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
