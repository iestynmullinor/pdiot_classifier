{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GYRO = False\n",
    "SEQUENCE_LENGTH = 3\n",
    "SEQUENCE_OVERLAP = 2\n",
    "MODEL_NAME = \"physical_activity_with_dropout_without_gyro.keras\"\n",
    "BATCH_SIZE = 5\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDIT THE VALUES IN THE CELL ABOVE THEN PRESS RUN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_tagger\n",
    "import sequence_genrator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import layers, Sequential, models\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"./all_respeck\"\n",
    "PHYSICAL_ACTIVITIES = {\n",
    "    \"ascending_stairs&normal_breathing\",\n",
    "    \"shuffle_walking&normal_breathing\",\n",
    "    \"walking&normal_breathing\",\n",
    "    \"descending_stairs&normal_breathing\",\n",
    "    \"misc_movements&normal_breathing\",\n",
    "    \"running&normal_breathing\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(directory, sequence_length, overlap, gyro = GYRO): # if gyro is false, only accelerometer data is used\n",
    "\n",
    "    tagged_data = []\n",
    "\n",
    "    # group each csv file into their respective areas\n",
    "    csv_dictionary = file_tagger.tag_directory(directory)\n",
    "\n",
    "    # iterates through each activity\n",
    "    for key in PHYSICAL_ACTIVITIES:\n",
    "\n",
    "        # iterates through each csv file for the activity \n",
    "        for csv_file in csv_dictionary[key]:\n",
    "            if gyro:\n",
    "                sequences = sequence_genrator.generate_sequences_from_file_with_gyroscope(directory + \"/\" + csv_file, sequence_length, overlap)\n",
    "            else:\n",
    "                sequences = sequence_genrator.generate_sequences_from_file_without_gyroscope(directory + \"/\" + csv_file, sequence_length, overlap)\n",
    "\n",
    "            # iterate through each generated sequence\n",
    "            for sequence in sequences:\n",
    "                tagged_data.append((key, sequence))\n",
    "\n",
    "    print (\"there are \" + str(len(tagged_data)) + \" tagged sequences in the dataset\")\n",
    "    return tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training, dev, and test sets\n",
    "def train_dev_test_split(data, labels, dev_size, test_size, random_state=42):\n",
    "    # Split the data into training and temporary (dev + test) sets\n",
    "    train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=(dev_size + test_size), random_state=random_state)\n",
    "    \n",
    "    # Split the temporary data into dev and test sets\n",
    "    dev_data, test_data, dev_labels, test_labels = train_test_split(temp_data, temp_labels, \n",
    "                                                                 test_size=(test_size / (dev_size + test_size)), random_state=random_state)\n",
    "    \n",
    "    return train_data, dev_data, test_data, train_labels, dev_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 7715 tagged sequences in the dataset\n"
     ]
    }
   ],
   "source": [
    "tagged_sequences = generate_training_data(DATA_DIRECTORY, SEQUENCE_LENGTH, SEQUENCE_OVERLAP)\n",
    "\n",
    "# Combine all sequences and labels\n",
    "sequences = [sequence for _, sequence in tagged_sequences]\n",
    "labels = [label for label, _ in tagged_sequences]\n",
    "\n",
    "\n",
    "# encode labels to numbers\n",
    "sequences = np.array(sequences, dtype=np.float32)\n",
    "label_to_index = {label: idx for idx, label in enumerate(PHYSICAL_ACTIVITIES)}\n",
    "labels_encoded = [label_to_index[label] for label in labels]\n",
    "labels_encoded = np.array(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN MODEL\n",
    "def train_model_CNN(input_data, labels_encoded, unique_labels, epochs, batch_size, validation_data):\n",
    "    if GYRO:\n",
    "        width = 6\n",
    "    else:\n",
    "        width = 3\n",
    "    # Define the CNN model for your specific input shape\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(32, 3, activation='relu', input_shape=(SEQUENCE_LENGTH*25, width)),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu', input_shape=(SEQUENCE_LENGTH*25, width)),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(len(unique_labels), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the CNN model\n",
    "    model.fit(input_data, labels_encoded, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1235/1235 [==============================] - 4s 2ms/step - loss: 1.0954 - accuracy: 0.5541 - val_loss: 0.8326 - val_accuracy: 0.6913\n",
      "Epoch 2/40\n",
      "1235/1235 [==============================] - 4s 3ms/step - loss: 0.6152 - accuracy: 0.7644 - val_loss: 0.4987 - val_accuracy: 0.8145\n",
      "Epoch 3/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.4581 - accuracy: 0.8312 - val_loss: 0.3813 - val_accuracy: 0.8690\n",
      "Epoch 4/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.3689 - accuracy: 0.8662 - val_loss: 0.3044 - val_accuracy: 0.8949\n",
      "Epoch 5/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.3176 - accuracy: 0.8829 - val_loss: 0.2745 - val_accuracy: 0.9066\n",
      "Epoch 6/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.2533 - accuracy: 0.9099 - val_loss: 0.2212 - val_accuracy: 0.9248\n",
      "Epoch 7/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.2286 - accuracy: 0.9190 - val_loss: 0.2454 - val_accuracy: 0.9157\n",
      "Epoch 8/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.2032 - accuracy: 0.9243 - val_loss: 0.2155 - val_accuracy: 0.9157\n",
      "Epoch 9/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1842 - accuracy: 0.9357 - val_loss: 0.1634 - val_accuracy: 0.9455\n",
      "Epoch 10/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1698 - accuracy: 0.9399 - val_loss: 0.1393 - val_accuracy: 0.9520\n",
      "Epoch 11/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1604 - accuracy: 0.9446 - val_loss: 0.1576 - val_accuracy: 0.9533\n",
      "Epoch 12/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1422 - accuracy: 0.9516 - val_loss: 0.1299 - val_accuracy: 0.9598\n",
      "Epoch 13/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1321 - accuracy: 0.9559 - val_loss: 0.1671 - val_accuracy: 0.9442\n",
      "Epoch 14/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1407 - accuracy: 0.9512 - val_loss: 0.1492 - val_accuracy: 0.9481\n",
      "Epoch 15/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1208 - accuracy: 0.9564 - val_loss: 0.1286 - val_accuracy: 0.9611\n",
      "Epoch 16/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1174 - accuracy: 0.9595 - val_loss: 0.0983 - val_accuracy: 0.9715\n",
      "Epoch 17/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1168 - accuracy: 0.9603 - val_loss: 0.1105 - val_accuracy: 0.9624\n",
      "Epoch 18/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1191 - accuracy: 0.9577 - val_loss: 0.1011 - val_accuracy: 0.9624\n",
      "Epoch 19/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1093 - accuracy: 0.9642 - val_loss: 0.0795 - val_accuracy: 0.9728\n",
      "Epoch 20/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0980 - accuracy: 0.9660 - val_loss: 0.0918 - val_accuracy: 0.9689\n",
      "Epoch 21/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0954 - accuracy: 0.9681 - val_loss: 0.1029 - val_accuracy: 0.9715\n",
      "Epoch 22/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.1037 - accuracy: 0.9657 - val_loss: 0.0874 - val_accuracy: 0.9780\n",
      "Epoch 23/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0935 - accuracy: 0.9676 - val_loss: 0.0912 - val_accuracy: 0.9715\n",
      "Epoch 24/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0765 - accuracy: 0.9749 - val_loss: 0.1550 - val_accuracy: 0.9546\n",
      "Epoch 25/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0765 - accuracy: 0.9752 - val_loss: 0.1044 - val_accuracy: 0.9741\n",
      "Epoch 26/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0814 - accuracy: 0.9736 - val_loss: 0.0976 - val_accuracy: 0.9702\n",
      "Epoch 27/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0913 - accuracy: 0.9700 - val_loss: 0.0987 - val_accuracy: 0.9676\n",
      "Epoch 28/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 0.1025 - val_accuracy: 0.9741\n",
      "Epoch 29/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0790 - accuracy: 0.9742 - val_loss: 0.1032 - val_accuracy: 0.9611\n",
      "Epoch 30/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0742 - accuracy: 0.9755 - val_loss: 0.0859 - val_accuracy: 0.9754\n",
      "Epoch 31/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0812 - accuracy: 0.9742 - val_loss: 0.1034 - val_accuracy: 0.9715\n",
      "Epoch 32/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 0.1062 - val_accuracy: 0.9598\n",
      "Epoch 33/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0877 - accuracy: 0.9750 - val_loss: 0.0969 - val_accuracy: 0.9663\n",
      "Epoch 34/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0686 - accuracy: 0.9796 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
      "Epoch 35/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0735 - accuracy: 0.9759 - val_loss: 0.1009 - val_accuracy: 0.9689\n",
      "Epoch 36/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 0.1025 - val_accuracy: 0.9702\n",
      "Epoch 37/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0750 - accuracy: 0.9768 - val_loss: 0.1058 - val_accuracy: 0.9637\n",
      "Epoch 38/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.0785 - val_accuracy: 0.9754\n",
      "Epoch 39/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0725 - accuracy: 0.9789 - val_loss: 0.0961 - val_accuracy: 0.9715\n",
      "Epoch 40/40\n",
      "1235/1235 [==============================] - 3s 2ms/step - loss: 0.0664 - accuracy: 0.9789 - val_loss: 0.0778 - val_accuracy: 0.9780\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9741\n",
      "Test Loss: 0.06478627026081085, Test Accuracy: 0.9740932583808899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 16:51:58.240097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-11-03 16:51:58.562007: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,32]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/physical_activity_with_dropout_without_gyro.keras_0.9740932583808899/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/physical_activity_with_dropout_without_gyro.keras_0.9740932583808899/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, dev_data, test_data, train_labels, dev_labels, test_labels = train_dev_test_split(sequences, labels_encoded, dev_size=0.1, test_size=0.1) #10% dev, 10% test\n",
    "\n",
    "\n",
    "# train and save model (CHOOSE BETWEEN CNN AND LSTM)\n",
    "model = train_model_CNN(train_data, train_labels, PHYSICAL_ACTIVITIES, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(dev_data, dev_labels)) #batch_size, epochs\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(f\"models/{MODEL_NAME}_{test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
